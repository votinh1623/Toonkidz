import axios from 'axios';
import { AI_MODELS, AI_RETRY_OPTIONS } from '../config/ai.config.js';
import themes from "../config/theme.config.js"

export const generateStory = async (req, res) => {
  const { theme, keywords, prompt: userPrompt } = req.body;

  // ‚úÖ 1Ô∏è‚É£ Require at least a theme or a user prompt
  if (!theme && !userPrompt) {
    return res.status(400).json({ error: 'Theme or prompt is required' });
  }

  const storyKeywords = Array.isArray(keywords) && keywords.length > 0 ? keywords : [];

  // ‚úÖ 2Ô∏è‚É£ Build the instruction
  const basePrompt = userPrompt
    ? `ƒê√ÇY L√Ä √ù T∆Ø·ªûNG NG∆Ø·ªúI D√ôNG G√ï TR·ª∞C TI·∫æP (∆∞u ti√™n cao nh·∫•t): *${userPrompt}*`
    : `CH·ª¶ ƒê·ªÄ: "${theme}"`;

  const prompt = `
${basePrompt}

T·∫°o m·ªôt c√¢u chuy·ªán thi·∫øu nhi b·∫±ng ti·∫øng Vi·ªát v·ªõi c√°c y√™u c·∫ßu sau:

T·ª™ KH√ìA B·∫ÆT BU·ªòC (n·∫øu c√≥): ${storyKeywords.length ? storyKeywords.join(', ') : 'Kh√¥ng c√≥ t·ª´ kh√≥a b·∫Øt bu·ªôc.'}

Y√äU C·∫¶U:
1. Ti√™u ƒë·ªÅ: M·ªôt d√≤ng ng·∫Øn g·ªçn, h·∫•p d·∫´n.
2. T√≥m t·∫Øt: M·ªôt ho·∫∑c hai c√¢u m√¥ t·∫£ n·ªôi dung ch√≠nh c·ªßa c√¢u chuy·ªán, kh√¥ng ch·ª©a "m·ªôt c√¢u chuy·ªán...".
3. C√¢u chuy·ªán: Kho·∫£ng 10 t·ª´, vi·∫øt b·∫±ng ng√¥n ng·ªØ ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu cho tr·∫ª em t·ª´ 5-10 tu·ªïi.
4. K·∫øt c·∫•u c√¢u chuy·ªán r√µ r√†ng: m·ªü ƒë·∫ßu, di·ªÖn bi·∫øn, k·∫øt th√∫c, kh√¥ng c·∫ßn ghi r√µ ra.

ƒê·ªäNH D·∫†NG ƒê·∫¶U RA (JSON):
{
  "title": "Ti√™u ƒë·ªÅ c√¢u chuy·ªán",
  "heading": "T√≥m t·∫Øt ng·∫Øn g·ªçn",
  "story": "N·ªôi dung c√¢u chuy·ªán ƒë·∫ßy ƒë·ªß..."
}

L∆∞u √Ω:
- Vi·∫øt to√†n b·ªô c√¢u chuy·ªán b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n.
- ∆Øu ti√™n tuy·ªát ƒë·ªëi √Ω t∆∞·ªüng do ng∆∞·ªùi d√πng g√µ (*${userPrompt || theme}*).
- S·ª≠ d·ª•ng t·ª´ kh√≥a m·ªôt c√°ch t·ª± nhi√™n, kh√¥ng g∆∞·ª£ng √©p.
- C√¢u chuy·ªán c√≥ t√≠nh gi√°o d·ª•c, vui v·∫ª v√† ph√π h·ª£p v·ªõi tr·∫ª em.
`;

  const sortedModels = AI_MODELS.sort((a, b) => a.priority - b.priority);

  for (const model of sortedModels) {
    let attempt = 0;

    while (attempt < (AI_RETRY_OPTIONS.maxRetries || 1)) {
      try {
        let storyText = '';

        // üÜï REPLICATE INTEGRATION (Claude 3.7 Sonnet)
        if (model.provider === 'replicate') {
          const response = await axios.post(
            model.endpoint,
            {
              input: {
                prompt: prompt,
                system_prompt: "B·∫°n l√† m·ªôt nh√† vƒÉn chuy√™n vi·∫øt truy·ªán thi·∫øu nhi. H√£y vi·∫øt c√¢u chuy·ªán b·∫±ng ti·∫øng Vi·ªát.",
                max_tokens: 1200,
                temperature: 0.8
              }
            },
            {
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Token ${process.env[model.envKey]}`
              },
              timeout: AI_RETRY_OPTIONS.timeoutMs
            }
          );
          
          // Replicate responses are often async, check for completion
          if (response.data.status === 'succeeded') {
            storyText = response.data.output.join('');
          } else if (response.data.output) {
            storyText = Array.isArray(response.data.output) 
              ? response.data.output.join('') 
              : response.data.output;
          } else {
            throw new Error('Replicate response not ready');
          }
        }

        // DEEPSEEK INTEGRATION
        else if (model.provider === 'deepseek') {
          const response = await axios.post(
            model.endpoint,
            {
              model: model.model,
              messages: [
                {
                  role: "user",
                  content: prompt
                }
              ],
              temperature: 0.8,
              max_tokens: 1200,
              stream: false
            },
            {
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env[model.envKey]}`
              },
              timeout: AI_RETRY_OPTIONS.timeoutMs
            }
          );
          storyText = response.data.choices[0].message.content;
        }

        // GOOGLE GEMINI INTEGRATION
        else if (model.provider === 'google') {
          const response = await axios.post(
            `${model.endpoint}?key=${process.env.GEMINI_API_KEY}`,
            {
              contents: [
                {
                  role: "user",
                  parts: [{ text: prompt }]
                }
              ],
              generation_config: {
                temperature: 0.8,
                max_output_tokens: 1500
              }
            },
            {
              headers: { 'Content-Type': 'application/json' },
              timeout: AI_RETRY_OPTIONS.timeoutMs
            }
          );
          storyText = response.data.candidates?.[0]?.content?.parts?.[0]?.text || '';
        }

        // HUGGINGFACE INTEGRATION
        else if (model.provider === 'huggingface') {
          const response = await axios.post(
            model.endpoint,
            {
              model: model.model,
              messages: [
                {
                  role: "user",
                  content: prompt
                }
              ],
              temperature: 0.8,
              max_tokens: 1500
            },
            {
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env[model.envKey]}`
              },
              timeout: AI_RETRY_OPTIONS.timeoutMs
            }
          );
          storyText = response.data.choices?.[0]?.message?.content || '';
        }

        // POLLINATIONS INTEGRATION
        else if (model.provider === 'pollinations') {
          const encodedPrompt = encodeURIComponent(prompt);
          const response = await axios.get(
            `${model.endpoint}/${encodedPrompt}`,
            { timeout: AI_RETRY_OPTIONS.timeoutMs }
          );

          if (typeof response.data === 'string') {
            storyText = response.data;
          } else if (response.data && typeof response.data === 'object') {
            storyText = response.data.text ||
              response.data.content ||
              response.data.generated_text ||
              response.data.output ||
              JSON.stringify(response.data);
          } else {
            storyText = String(response.data || '');
          }
        }

        // Ensure storyText is always a string
        storyText = String(storyText || '');

        if (!storyText || storyText.trim() === '') throw new Error('Empty response from AI');

        let result;
        try {
          result = JSON.parse(storyText);
        } catch {
          // fallback parsing logic
          const lines = storyText.split('\n').map(l => l.trim()).filter(Boolean);
          let title = '', heading = '', story = '';
          lines.forEach(line => {
            const lower = line.toLowerCase();
            if (!title && (lower.startsWith('title:') || lower.startsWith('ti√™u ƒë·ªÅ:')))
              title = line.replace(/title:|ti√™u ƒë·ªÅ:/i, '').trim();
            else if (!heading && (lower.startsWith('heading:') || lower.startsWith('t√≥m t·∫Øt:') || lower.startsWith('summary:')))
              heading = line.replace(/heading:|t√≥m t·∫Øt:|summary:/i, '').trim();
            else if (!story && (lower.startsWith('story:') || lower.startsWith('c√¢u chuy·ªán:') || lower.startsWith('n·ªôi dung:')))
              story = line.replace(/story:|c√¢u chuy·ªán:|n·ªôi dung:/i, '').trim();
          });

          if (!story) story = lines.join(' ');
          if (!title) title = `C√¢u chuy·ªán v·ªÅ ${theme}`;
          if (!heading) heading = 'M·ªôt c√¢u chuy·ªán th√∫ v·ªã d√†nh cho tr·∫ª em';
          if (!story) story = storyText;

          result = { title, heading, story };
        }

        return res.json({
          ...result,
          keywords: storyKeywords,
          theme: theme,
          model_used: model.name // Track which model succeeded
        });

      } catch (err) {
        console.warn(`Attempt ${attempt + 1} failed for model ${model.name}:`, err.message);
        
        // üÜï AUTOMATIC MODEL SWITCHING CONDITIONS
        const errorMessage = err.message?.toLowerCase() || '';
        const responseData = err.response?.data;
        
        // Check for token limits, quota exceeded, or rate limits
        const shouldSwitchModel = 
          errorMessage.includes('token') ||
          errorMessage.includes('quota') ||
          errorMessage.includes('limit') ||
          errorMessage.includes('rate') ||
          errorMessage.includes('billing') ||
          errorMessage.includes('payment') ||
          errorMessage.includes('exceeded') ||
          (responseData && (
            (responseData.error?.message?.toLowerCase().includes('token')) ||
            (responseData.error?.message?.toLowerCase().includes('quota')) ||
            (responseData.error?.message?.toLowerCase().includes('limit')) ||
            (responseData.error?.message?.toLowerCase().includes('billing'))
          ));

        if (shouldSwitchModel) {
          console.warn(`Model ${model.name} reached limits, switching to next model...`);
          break; // Break out of retry loop and move to next model
        }

        if (err.response) {
          console.warn('Error response data:', err.response.data);
        }
        attempt++;
      }
    }

    console.warn(`Model ${model.name} failed all attempts, trying next model...`);
  }

  return res.status(500).json({ 
    error: 'All AI models failed to generate story',
    message: 'Xin l·ªói, t·∫•t c·∫£ c√°c d·ªãch v·ª• AI hi·ªán ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng th·ª≠ l·∫°i sau.'
  });
};